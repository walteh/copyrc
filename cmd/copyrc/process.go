// Copyright 2025 walteh LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package main

import (
	"bytes"
	"context"
	"fmt"
	"io"
	"net/http"
	"os"
	"path/filepath"
	"slices"
	"strings"
	"sync"
	"time"

	"github.com/bmatcuk/doublestar/v4"
	"gitlab.com/tozd/go/errors"
)

var (
	processedFiles sync.Map
	loggerMu       sync.Mutex
)

func logFileOperation(ctx context.Context, opts FileInfo) {
	logger := loggerFromContext(ctx)
	logger.LogFileOperation(opts)
	// if _, loaded := processedFiles.LoadOrStore(opts.Name, true); !loaded {
	// 	loggerMu.Lock()
	// 	defer loggerMu.Unlock()

	// 	logger.LogFileOperation(opts)
	// }
}

// üßπ Clean destination directory
func cleanDestination(ctx context.Context, status *StatusFile, destPath string) error {
	logger := loggerFromContext(ctx)

	for _, entry := range status.CoppiedFiles {
		logger.AddFileOperation(FileInfo{Name: entry.File, IsRemoved: true})
		if err := os.Remove(filepath.Join(destPath, entry.File)); err != nil {
			return errors.Errorf("removing file: %w", err)
		}
	}

	for _, entry := range status.GeneratedFiles {
		logger.AddFileOperation(FileInfo{Name: entry.File, IsRemoved: true})
		if err := os.Remove(filepath.Join(destPath, entry.File)); err != nil {
			return errors.Errorf("removing file: %w", err)
		}
	}

	logger.AddFileOperation(FileInfo{Name: ".copyrc.lock", IsRemoved: true})
	if err := os.Remove(filepath.Join(destPath, ".copyrc.lock")); err != nil {
		if !os.IsNotExist(err) {
			return errors.Errorf("removing status file: %w", err)
		}
	}

	return nil
}

type FileGetter interface {
	GetFile(ctx context.Context, args Source, file string) ([]byte, error)
}

func processArchive(ctx context.Context, provider RepoProvider, src Source, dest Destination, args *ArchiveEntry_Options, commitHash string, status *StatusFile, mu *sync.Mutex) error {

	if src.Path != "" {
		return errors.New("path is not supported in tarball mode")
	}

	// Ensure cache directory exists
	repoName := filepath.Base(src.Repo)
	if err := os.MkdirAll(dest.Path, 0755); err != nil {
		return errors.Errorf("creating repo directory: %w", err)
	}

	// Download tarball
	data, err := GetFileFromTarball(ctx, provider, src)
	if err != nil {
		return errors.Errorf("getting file from tarball: %w", err)
	}
	tarballPath := filepath.Join(dest.Path, repoName+".tar.gz")

	// Save tarball
	sourceInfo, err := provider.GetSourceInfo(ctx, src, commitHash)
	if err != nil {
		return errors.Errorf("getting source info: %w", err)
	}

	permalink, err := provider.GetArchiveUrl(ctx, src)
	if err != nil {
		return errors.Errorf("getting permalink: %w", err)
	}

	// Let writeFile handle status determination
	if _, err := writeFile(ctx, WriteFileOpts{
		SourcePath:     tarballPath,
		Destination:    dest,
		Path:           tarballPath,
		Contents:       data,
		StatusFile:     status,
		StatusMutex:    mu,
		RepoSourceInfo: sourceInfo,
		Permalink:      permalink,
	}); err != nil {
		return errors.Errorf("writing tarball: %w", err)
	}

	if args != nil && args.GoEmbed {

		mu.Lock()
		tarStatus := status.CoppiedFiles[filepath.Base(tarballPath)]
		mu.Unlock()

		// Create embed.go file
		pkgName := strings.ReplaceAll(repoName, "-", "")
		embedPath := filepath.Join(dest.Path, "embed.gen.go")
		var buf bytes.Buffer

		fmt.Fprintf(&buf, "// üì¶ generated by copyrc. DO NOT EDIT.\n")
		fmt.Fprintf(&buf, "// ‚ÑπÔ∏è see .copyrc.lock for more details.\n\n")
		fmt.Fprintf(&buf, "package %s\n\n", pkgName)
		fmt.Fprintf(&buf, "import _ \"embed\"\n\n")
		fmt.Fprintf(&buf, "//go:embed %s.tar.gz\n", repoName)
		fmt.Fprintf(&buf, "var Data []byte\n\n")
		fmt.Fprintf(&buf, "// Metadata about the downloaded repository\n")
		fmt.Fprintf(&buf, "var (\n")
		fmt.Fprintf(&buf, "\tRef        = %q\n", src.Ref)
		fmt.Fprintf(&buf, "\tCommit     = %q\n", commitHash)
		fmt.Fprintf(&buf, "\tRepository = %q\n", src.Repo)
		fmt.Fprintf(&buf, "\tPermalink  = %q\n", permalink)
		fmt.Fprintf(&buf, "\tDownloaded = %q\n", tarStatus.LastUpdated.Format(time.RFC3339))
		fmt.Fprintf(&buf, ")\n")

		// Let writeFile handle status determination
		if _, err := writeFile(ctx, WriteFileOpts{
			SourcePath:    embedPath,
			Destination:   dest,
			Path:          embedPath,
			Contents:      buf.Bytes(),
			IsManaged:     true,
			StatusFile:    status,
			StatusMutex:   mu,
			EnsureNewline: true,
		}); err != nil {
			return errors.Errorf("writing embed.gen.go: %w", err)
		}

	}

	return nil

}

func (me *ProviderFile) OutPathWithExtensionPrefix(prefix string) string {
	if prefix != "" {
		return strings.TrimSuffix(me.Path, filepath.Ext(me.Path)) + "." + strings.TrimPrefix(prefix, ".") + filepath.Ext(me.Path)
	}
	return me.Path
}

func processCopy(ctx context.Context, provider RepoProvider, src Source, dest Destination, args *CopyEntry_Options, commitHash string, status *StatusFile, mu *sync.Mutex, file ProviderFile) error {

	if err := os.MkdirAll(dest.Path, 0755); err != nil {
		return errors.Errorf("creating destination directory: %w", err)
	}

	if args != nil {
		// Check file patterns first before doing anything else
		if len(args.FilePatterns) > 0 {
			matched := false
			for _, pattern := range args.FilePatterns {
				if match, err := doublestar.Match(pattern, file.Path); err == nil && match {
					matched = true
					break
				}
			}
			if !matched {
				return nil
			}
		}

		// Check ignore patterns
		for _, pattern := range args.IgnoreFiles {
			if match, err := doublestar.Match(pattern, file.Path); err == nil && match {
				// Skip this file
				return nil
			}
		}
	}

	sourceInfo, err := provider.GetSourceInfo(ctx, src, commitHash)
	if err != nil {
		return errors.Errorf("getting source info: %w", err)
	}

	permalink, err := provider.GetPermalink(ctx, src, commitHash, file.Path)
	if err != nil {
		return errors.Errorf("getting permalink: %w", err)
	}

	var contentz []byte
	if mockProvider, ok := provider.(FileGetter); ok {
		// For mock provider, use GetFile directly
		contentz, err = mockProvider.GetFile(ctx, src, file.Path)
		if err != nil {
			return errors.Errorf("getting file content: %w", err)
		}
	} else if strings.HasPrefix(permalink, "file://") {
		contentz, err = os.ReadFile(strings.TrimPrefix(permalink, "file://"))
		if err != nil {
			return errors.Errorf("reading file: %w", err)
		}
	} else {
		req, err := http.NewRequestWithContext(ctx, "GET", permalink, nil)
		if err != nil {
			return errors.Errorf("creating request: %w", err)
		}

		resp, err := http.DefaultClient.Do(req)
		if err != nil {
			return errors.Errorf("downloading file: %w", err)
		}
		defer resp.Body.Close()

		if resp.StatusCode != http.StatusOK {
			return errors.Errorf("downloading file: %s", resp.Status)
		}

		contentz, err = io.ReadAll(resp.Body)
		if err != nil {
			return errors.Errorf("reading file: %w", err)
		}
	}

	outPath := file.Path
	if args != nil && args.ExtensionPrefix != "" {
		outPath = file.OutPathWithExtensionPrefix(args.ExtensionPrefix)
	}
	outPath = strings.TrimPrefix(outPath, src.Path+"/")
	outPath = filepath.Join(dest.Path, outPath)

	if err := os.MkdirAll(filepath.Dir(outPath), 0755); err != nil {
		return errors.Errorf("creating output directory: %w", err)
	}

	// Process content
	var buf bytes.Buffer

	if args == nil || !args.NoHeaderComments {
		// Add file header based on extension
		switch filepath.Ext(file.Path) {
		case ".go", ".js", ".ts", ".jsx", ".tsx", ".cpp", ".c", ".h", ".hpp", ".java", ".scala", ".rs", ".php", "jsonc":
			fmt.Fprintf(&buf, "// üì¶ originally copied by copyrc\n")
			fmt.Fprintf(&buf, "// üîó source: %s\n", permalink)
			fmt.Fprintf(&buf, "// üìù license: %s\n", status.License.SPDX)
			fmt.Fprintf(&buf, "// ‚ÑπÔ∏è see .copyrc.lock for more details\n\n")
		case ".py", ".rb", ".pl", ".sh", ".yaml", ".yml":
			fmt.Fprintf(&buf, "# üì¶ originally copied by copyrc\n")
			fmt.Fprintf(&buf, "# üîó source: %s\n", permalink)
			fmt.Fprintf(&buf, "# üìù license: %s\n", status.License.SPDX)
			fmt.Fprintf(&buf, "# ‚ÑπÔ∏è see .copyrc.lock for more details\n\n")
		case ".md", ".xml":
			fmt.Fprintf(&buf, "<!--\n")
			fmt.Fprintf(&buf, "üì¶ originally copied by copyrc\n")
			fmt.Fprintf(&buf, "üîó source: %s\n", permalink)
			fmt.Fprintf(&buf, "üìù license: %s\n", status.License.SPDX)
			fmt.Fprintf(&buf, "‚ÑπÔ∏è see .copyrc.lock for more details\n")
			fmt.Fprintf(&buf, "-->\n\n")
		}
	}

	// Write original content
	buf.Write(contentz)
	var replacementCount int
	var changes []string
	if args != nil {
		// Apply replacements

		for _, r := range args.Replacements {
			if r.File != nil && *r.File != "" {
				matched, err := doublestar.Match(*r.File, file.Path)
				if err != nil {
					return errors.Errorf("matching file: %w", err)
				}
				if !matched {
					continue
				}
			}
			if bytes.Contains(buf.Bytes(), []byte(r.Old)) {
				// Count occurrences of the replacement
				replacementCount += bytes.Count(buf.Bytes(), []byte(r.Old))

				// Find line numbers for the changes
				lines := bytes.Split(buf.Bytes(), []byte("\n"))
				for i, line := range lines {
					if bytes.Contains(line, []byte(r.Old)) {
						change := fmt.Sprintf("Line %d: Replaced '%s' with '%s'", i+1, r.Old, r.New)
						changes = append(changes, change)
					}
				}

				// Apply the replacement
				newContent := bytes.ReplaceAll(buf.Bytes(), []byte(r.Old), []byte(r.New))
				buf.Reset()
				buf.Write(newContent)
			}
		}
	}

	// Let writeFile handle all status management and logging
	if _, err := writeFile(ctx, WriteFileOpts{
		SourcePath:       file.Path,
		Destination:      dest,
		Path:             outPath,
		Contents:         buf.Bytes(),
		StatusFile:       status,
		StatusMutex:      mu,
		RepoSourceInfo:   sourceInfo,
		Permalink:        permalink,
		Changes:          changes,
		ReplacementCount: replacementCount,
		EnsureNewline:    true,
	}); err != nil {
		return errors.Errorf("writing file: %w", err)
	}

	return nil
}

func processDirectory(ctx context.Context, provider RepoProvider, cfg *SingleConfig, commitHash string, status *StatusFile, mu *sync.Mutex) error {
	// Ensure destination directory exists
	if err := os.MkdirAll(cfg.Destination.Path, 0755); err != nil {
		return errors.Errorf("creating destination directory: %w", err)
	}

	var files []ProviderFile
	var err error
	if cfg.ArchiveArgs != nil {
		// Get list of files from provider
		files = []ProviderFile{{Path: "dummy"}}
	} else if cfg.CopyArgs != nil {
		files, err = provider.ListFiles(ctx, cfg.Source, cfg.CopyArgs.Recursive)
		if err != nil {
			return errors.Errorf("listing files: %w", err)
		}
	} else {
		files, err = provider.ListFiles(ctx, cfg.Source, false)
		if err != nil {
			return errors.Errorf("listing files: %w", err)
		}
	}

	// Sort files by name
	slices.SortFunc(files, func(a, b ProviderFile) int {
		return strings.Compare(a.Path, b.Path)
	})

	longestNeighbor := 0
	for _, file := range files {
		if len(file.Path) > longestNeighbor {
			longestNeighbor = len(file.Path)
		}
	}

	logger := loggerFromContext(ctx)
	logger.longestNeighbor = longestNeighbor

	// Process each file
	if cfg.Flags.Async {
		var wg sync.WaitGroup
		errChan := make(chan error, len(files))

		for _, file := range files {
			wg.Add(1)
			go func(f ProviderFile) {
				defer wg.Done()
				if cfg.ArchiveArgs != nil {
					if err := processArchive(ctx, provider, cfg.Source, cfg.Destination, cfg.ArchiveArgs, commitHash, status, mu); err != nil {
						errChan <- errors.Errorf("processing file %s: %w", f.Path, err)
					}
				} else {
					if err := processCopy(ctx, provider, cfg.Source, cfg.Destination, cfg.CopyArgs, commitHash, status, mu, f); err != nil {
						errChan <- errors.Errorf("processing file %s: %w", f.Path, err)
					}
				}
			}(file)
		}

		// Wait for all goroutines to finish
		wg.Wait()
		close(errChan)

		// Check for errors
		for err := range errChan {
			if err != nil {
				return err
			}
		}
	} else {
		for _, file := range files {
			if file.Path == "dummy" && cfg.ArchiveArgs == nil {
				continue
			}
			if cfg.ArchiveArgs != nil {
				if err := processArchive(ctx, provider, cfg.Source, cfg.Destination, cfg.ArchiveArgs, commitHash, status, mu); err != nil {
					return errors.Errorf("processing file %s: %w", file.Path, err)
				}
			} else {

				if err := processCopy(ctx, provider, cfg.Source, cfg.Destination, cfg.CopyArgs, commitHash, status, mu, file); err != nil {
					return errors.Errorf("processing file %s: %w", file.Path, err)
				}
			}
		}
	}

	if err := processUntracked(ctx, status, cfg.Destination, cfg.CopyArgs != nil && cfg.CopyArgs.Recursive); err != nil {
		return errors.Errorf("processing untracked files: %w", err)
	}

	return nil
}

type EntryItem struct {
	Path string
	Info os.DirEntry
}

func allEntries(path string, recursive bool) ([]EntryItem, error) {
	entries, err := os.ReadDir(path)
	if err != nil {
		return nil, errors.Errorf("reading directory: %w", err)
	}
	copyrclockDirs := []string{}
	addEntries := []EntryItem{}
	for _, entry := range entries {
		if entry.Name() == ".copyrc.lock" {
			copyrclockDirs = append(copyrclockDirs, path)
		}
		if entry.IsDir() && recursive {
			subEntries, err := allEntries(filepath.Join(path, entry.Name()), recursive)
			if err != nil {
				return nil, errors.Errorf("reading directory: %w", err)
			}
			addEntries = append(addEntries, subEntries...)
		} else {
			addEntries = append(addEntries, EntryItem{Path: filepath.Join(path, entry.Name()), Info: entry})
		}
	}

	// remove all copyrclockDirs from addEntries
	for _, dir := range copyrclockDirs {
		addEntries = slices.DeleteFunc(addEntries, func(entry EntryItem) bool {
			return strings.HasPrefix(entry.Path, dir+"/")
		})
	}

	return addEntries, nil
}

func processUntracked(ctx context.Context, status *StatusFile, dest Destination, recursive bool) error {

	entries, err := allEntries(dest.Path, recursive)
	if err != nil {
		return errors.Errorf("reading directory: %w", err)
	}

	entries = slices.DeleteFunc(entries, func(entry EntryItem) bool {
		trimmedPath := strings.TrimPrefix(entry.Path, dest.Path+"/")

		_, genStatus := status.GeneratedFiles[trimmedPath]
		_, copyStatus := status.CoppiedFiles[trimmedPath]
		return genStatus || copyStatus || entry.Info.IsDir() || entry.Info.Name() == ".copyrc.lock" || entry.Info.Name() == ".git" || entry.Info.Name() == ".DS_Store"
	})

	slices.SortFunc(entries, func(a, b EntryItem) int {
		return strings.Compare(a.Path, b.Path)
	})

	for _, entry := range entries {
		trimmedPath := strings.TrimPrefix(entry.Path, dest.Path+"/")
		if _, err := writeFile(ctx, WriteFileOpts{
			Destination: dest,
			Path:        trimmedPath,
			SourcePath:  entry.Path,
			IsUntracked: true,
		}); err != nil {
			return errors.Errorf("writing untracked file: %w", err)
		}
	}

	return nil

}

func process(ctx context.Context, cfg *SingleConfig, provider RepoProvider) error {
	logger := loggerFromContext(ctx)

	logger.formatRepoDisplay(RepoDisplay{
		Name:        cfg.Source.Repo,
		Ref:         cfg.Source.Ref,
		Destination: cfg.Destination.Path,
		IsArchive:   cfg.ArchiveArgs != nil,
	})

	destPath := cfg.Destination.Path
	if cfg.ArchiveArgs != nil {
		destPath = filepath.Join(destPath, filepath.Base(cfg.Source.Repo))
	}

	// Determine status file location based on mode
	var statusFile string
	if cfg.ArchiveArgs != nil {
		statusFile = filepath.Join(destPath, ".copyrc.lock")
		// Create repo directory if it doesn't exist
		if err := os.MkdirAll(destPath, 0755); err != nil {
			return errors.Errorf("creating repo directory: %w", err)
		}
	} else {
		statusFile = filepath.Join(destPath, ".copyrc.lock")
	}

	status, err := loadStatusFile(statusFile)
	if err != nil || status == nil {
		status = &StatusFile{
			CoppiedFiles:   make(map[string]StatusEntry),
			GeneratedFiles: make(map[string]GeneratedFileEntry),
			Args: StatusFileArgs{
				SrcRepo: cfg.Source.Repo,
				SrcRef:  cfg.Source.Ref,
				SrcPath: cfg.Source.Path,
			},
		}
	}

	// Compare arguments
	argsAreSame := status.Args.SrcRepo == cfg.Source.Repo &&
		status.Args.SrcRef == cfg.Source.Ref &&
		status.Args.SrcPath == cfg.Source.Path

	// Compare copy arguments if they exist
	if status.Args.CopyArgs != nil && cfg.CopyArgs != nil {
		// Compare replacements
		if len(status.Args.CopyArgs.Replacements) != len(cfg.CopyArgs.Replacements) {
			argsAreSame = false
		} else {
			for i, r := range status.Args.CopyArgs.Replacements {
				if r.Old != cfg.CopyArgs.Replacements[i].Old ||
					r.New != cfg.CopyArgs.Replacements[i].New {
					argsAreSame = false
					break
				}
			}
		}

		// Compare ignore files
		if len(status.Args.CopyArgs.IgnoreFiles) != len(cfg.CopyArgs.IgnoreFiles) {
			argsAreSame = false
		} else {
			for i, f := range status.Args.CopyArgs.IgnoreFiles {
				if f != cfg.CopyArgs.IgnoreFiles[i] {
					argsAreSame = false
					break
				}
			}
		}

		// Compare file patterns
		if len(status.Args.CopyArgs.FilePatterns) != len(cfg.CopyArgs.FilePatterns) {
			argsAreSame = false
		} else {
			for i, f := range status.Args.CopyArgs.FilePatterns {
				if f != cfg.CopyArgs.FilePatterns[i] {
					argsAreSame = false
					break
				}
			}
		}
	}
	// Check if arguments have changed
	if (cfg.Flags.Status || cfg.Flags.RemoteStatus) && !cfg.Flags.Force {
		if !argsAreSame {
			return errors.New("configuration has changed")
		}
		// For local status check, we're done
		if cfg.Flags.Status && !cfg.Flags.RemoteStatus {
			return nil
		}
	}

	if cfg.Flags.Clean {

		if err := cleanDestination(ctx, status, destPath); err != nil {
			return errors.Errorf("cleaning destination: %w", err)
		}

		if err := processUntracked(ctx, status, cfg.Destination, cfg.CopyArgs != nil && cfg.CopyArgs.Recursive); err != nil {
			return errors.Errorf("processing untracked files: %w", err)
		}

		// for all
		logger.LogNewline()
		return nil
	}

	commitHash, err := provider.GetCommitHash(ctx, cfg.Source)
	if err != nil {
		return errors.Errorf("getting commit hash: %w", err)
	}
	var mu sync.Mutex

	if !cfg.Flags.Force && !cfg.Flags.Clean && status.CommitHash != "" {
		if status.CommitHash == commitHash && argsAreSame {
			logger.longestNeighbor = status.GetLongestNeighbor()

			// loop through all files in status and print them out
			for _, file := range status.OrderedCoppiedFiles() {
				if _, err := writeFile(ctx, WriteFileOpts{
					SourcePath:    filepath.Join(cfg.Source.Path, file.File),
					Destination:   cfg.Destination,
					Path:          filepath.Join(cfg.Destination.Path, file.File),
					Contents:      nil,
					IsManaged:     false,
					StatusFile:    status,
					StatusMutex:   &mu,
					EnsureNewline: true,
				}); err != nil {
					return errors.Errorf("writing embed.gen.go: %w", err)
				}
			}
			for _, file := range status.OrderedGeneratedFiles() {
				if filepath.Base(file.File) == ".copyrc.lock" {
					continue
				}
				if _, err := writeFile(ctx, WriteFileOpts{
					SourcePath:    filepath.Join(cfg.Source.Path, file.File),
					Destination:   cfg.Destination,
					Path:          filepath.Join(cfg.Destination.Path, file.File),
					Contents:      nil,
					IsManaged:     true,
					StatusFile:    status,
					StatusMutex:   &mu,
					EnsureNewline: true,
				}); err != nil {
					return errors.Errorf("writing embed.gen.go: %w", err)
				}
			}
			if err := processUntracked(ctx, status, cfg.Destination, cfg.CopyArgs != nil && cfg.CopyArgs.Recursive); err != nil {
				return errors.Errorf("processing untracked files: %w", err)
			}
			defer func() {
				logger.LogNewline()
			}()

			return writeStatusFile(ctx, status, destPath)

		}
		if cfg.Flags.Status || cfg.Flags.RemoteStatus {
			return errors.New("files are out of date")
		}
	}

	license, err := provider.GetLicense(ctx, cfg.Source, commitHash)
	if err != nil {
		return errors.Errorf("getting license: %w", err)
	}

	status.License = license

	// Reset processed files map for each repository
	processedFiles = sync.Map{}

	if err := processDirectory(ctx, provider, cfg, commitHash, status, &mu); err != nil {
		return errors.Errorf("processing directory: %w", err)
	}

	status.CommitHash = commitHash
	status.Ref = cfg.Source.Ref
	status.Args = StatusFileArgs{
		SrcRepo:     cfg.Source.Repo,
		SrcRef:      cfg.Source.Ref,
		SrcPath:     cfg.Source.Path,
		CopyArgs:    cfg.CopyArgs,
		ArchiveArgs: cfg.ArchiveArgs,
	}

	dest := cfg.Destination.Path
	if cfg.ArchiveArgs != nil {
		dest = filepath.Join(dest, filepath.Base(cfg.Source.Repo))
	}

	if err := writeStatusFile(ctx, status, dest); err != nil {
		return errors.Errorf("writing status file: %w", err)
	}

	logger.LogNewline()

	return nil
}
